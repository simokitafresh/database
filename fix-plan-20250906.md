# æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç®¡ç†åŸºç›¤ - ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒ—ãƒ©ãƒ³ï¼ˆæ”¹è¨‚ç‰ˆï¼‰

## ğŸ“… ä½œæˆæ—¥: 2025å¹´9æœˆ6æ—¥
## ğŸ¯ ç›®çš„: Supabase + Render Starter Planç’°å¢ƒã§ã®å®‰å®šç¨¼åƒ + è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—æ©Ÿèƒ½

---

## 1. ğŸ”´ æœ€å„ªå…ˆ: queries_new.py - SQLAlchemyæ§‹æ–‡ã‚¨ãƒ©ãƒ¼

### WHYï¼ˆãªãœä¿®æ­£ãŒå¿…è¦ã‹ï¼‰
- **bindparamæ§‹æ–‡ã‚¨ãƒ©ãƒ¼**ã«ã‚ˆã‚Šã€ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’importã™ã‚‹ã¨å³åº§ã«AttributeErrorãŒç™ºç”Ÿ
- queries.pyãŒæ­£å¸¸å‹•ä½œã—ã¦ã„ã‚‹ãŒã€èª¤ã£ã¦queries_new.pyãŒå‘¼ã°ã‚Œã‚‹ã¨APIå…¨ä½“ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥
- åˆ¥ã‚¢ãƒ—ãƒªã‹ã‚‰APIã‚’å©ã„ãŸéš›ã«500ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™åŸå› 

### WHATï¼ˆä½•ã‚’ä¿®æ­£ã™ã‚‹ã‹ï¼‰
- queries_new.pyã®å‰Šé™¤ã¾ãŸã¯bindparamæ§‹æ–‡ã®ä¿®æ­£
- æ­£å¸¸å‹•ä½œã—ã¦ã„ã‚‹queries.pyã®ç¶­æŒ

### AS-ISï¼ˆç¾çŠ¶ï¼‰
```python
# app/db/queries_new.py - è¡Œ67-73
sql = text(
    """
    WITH rng AS (
        SELECT :date_from::date AS dfrom, :date_to::date AS dto
    ),
    ...
    """
).bindparam(  # âŒ AttributeError: 'TextClause' object has no attribute 'bindparam'
    bindparam("symbol", String),
    bindparam("date_from", Date),
    bindparam("date_to", Date)
)
```

### TO-BEï¼ˆä¿®æ­£å¾Œï¼‰
**ã‚ªãƒ—ã‚·ãƒ§ãƒ³1: queries_new.pyã‚’å‰Šé™¤ï¼ˆæ¨å¥¨ï¼‰**
```bash
# ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
rm app/db/queries_new.py
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³2: æ§‹æ–‡ä¿®æ­£**
```python
# app/db/queries_new.py - ä¿®æ­£ç‰ˆ
from sqlalchemy import bindparam

sql = text(
    """
    WITH rng AS (
        SELECT :date_from::date AS dfrom, :date_to::date AS dto
    ),
    ...
    """
)
# bindparamã¯åˆ¥é€”å®šç¾©ã€executeã§æ¸¡ã™
res = await session.execute(
    sql, 
    {"symbol": symbol, "date_from": date_from, "date_to": date_to}
)
```

---

## 2. ğŸ”´ Supabaseæ¥ç¶šæœ€é©åŒ–

### WHY
- Supabase Poolerãƒ¢ãƒ¼ãƒ‰ï¼ˆpgbouncerï¼‰ä½¿ç”¨æ™‚ã«prepared statementè¡çª
- æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šãŒSupabaseã®åˆ¶é™ã«åˆã£ã¦ã„ãªã„
- `statement_cache_size`ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤100ãŒåŸå› ã§ã‚¨ãƒ©ãƒ¼é »ç™º

### WHAT
- NullPoolä½¿ç”¨ï¼ˆpgbouncerçµŒç”±æ™‚ï¼‰
- statement_cacheç„¡åŠ¹åŒ–
- é©åˆ‡ãªæ¥ç¶šæ•°è¨­å®š

### AS-IS
```python
# app/db/engine.py
def create_engine_and_sessionmaker(
    database_url: str,
    pool_size: int = 5,  # å¤šã™ãã‚‹
    max_overflow: int = 5,
    ...
):
    # statement_cache_sizeã®è¨­å®šãªã—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ï¼‰
    connect_args = {}
```

### TO-BE
```python
# app/db/engine.py
def create_engine_and_sessionmaker(
    database_url: str,
    pool_size: int = 2,  # Starter Planå‘ã‘æœ€é©åŒ–
    max_overflow: int = 3,
    ...
):
    connect_args = {}
    poolclass = None
    
    if database_url.startswith("postgresql+asyncpg://"):
        # Supabaseå¿…é ˆè¨­å®š
        connect_args["statement_cache_size"] = 0  # å¿…é ˆ
        connect_args["prepared_statement_name_func"] = (
            lambda: f"__asyncpg_{uuid.uuid4()}__"
        )
        
        # Poolerä½¿ç”¨åˆ¤å®š
        if "pooler.supabase.com" in database_url:
            poolclass = NullPool  # pgbouncerçµŒç”±ã¯å¿…é ˆ
            logger.info("Using NullPool for Supabase Pooler mode")
```

---

## 3. ğŸ”´ entrypoint.shç°¡æ½”åŒ–

### WHY
- 400è¡Œè¶…ã®è¤‡é›‘ãªå‡¦ç†ã§ãƒ‡ãƒãƒƒã‚°å›°é›£
- ç’°å¢ƒå¤‰æ•°å‡¦ç†ã®è„†å¼±æ€§
- ã‚¨ãƒ©ãƒ¼æ™‚ã®åŸå› ç‰¹å®šãŒå›°é›£
- ãƒ‡ãƒ—ãƒ­ã‚¤å¤±æ•—ã®ä¸»è¦å› 

### WHAT
- ç’°å¢ƒå¤‰æ•°å‡¦ç†ã‚’10è¡Œä»¥å†…ã«
- æ˜ç¢ºãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- ä¸è¦ãªäº’æ›æ€§å‡¦ç†ã®å‰Šé™¤

### AS-IS
```bash
# docker/entrypoint.sh - è¤‡é›‘ãªç’°å¢ƒå¤‰æ•°å‡¦ç†
if '=' in url and url.startswith(('ALEMBIC_DATABASE_URL=', 'DATABASE_URL=')):
    url = url.split('=', 1)[1]
    print(f'[DEBUG] Cleaned URL after split: {repr(url)}')
# ... 400è¡Œä»¥ä¸Šã®å‡¦ç†
```

### TO-BE
```bash
#!/usr/bin/env bash
set -euo pipefail

# ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰
export ALEMBIC_DATABASE_URL="${ALEMBIC_DATABASE_URL:-${DATABASE_URL}}"

# URLãƒ‰ãƒ©ã‚¤ãƒãƒ¼å¤‰æ›ï¼ˆasyncpg â†’ psycopgï¼‰
if [[ "$ALEMBIC_DATABASE_URL" == *"asyncpg"* ]]; then
    export ALEMBIC_DATABASE_URL="${ALEMBIC_DATABASE_URL//asyncpg/psycopg}"
fi

echo "[entrypoint] Running migrations..."
alembic upgrade head || {
    echo "[entrypoint] Migration failed, attempting stamp..."
    alembic stamp head
}

echo "[entrypoint] Starting server..."
exec gunicorn app.main:app \
    --workers="${WEB_CONCURRENCY:-2}" \
    --worker-class=uvicorn.workers.UvicornWorker \
    --bind="0.0.0.0:${PORT:-8000}" \
    --timeout="${GUNICORN_TIMEOUT:-60}"  # 30â†’60ç§’ã«å¢—åŠ 
```

---

## 4. ğŸŸ¡ config.py - Starter Planæœ€é©åŒ–

### WHY
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãŒé–‹ç™ºç’°å¢ƒå‘ã‘
- Supabase + Renderã®åˆ¶é™ã‚’è€ƒæ…®ã—ã¦ã„ãªã„
- è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒçŸ­ã™ãã‚‹

### WHAT
- æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®šã®æœ€é©åŒ–
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã®èª¿æ•´ï¼ˆè‡ªå‹•å–å¾—å¯¾å¿œï¼‰

### AS-IS
```python
# app/core/config.py
DB_POOL_SIZE: int = 5
DB_MAX_OVERFLOW: int = 5
DB_POOL_RECYCLE: int = 1800
YF_REFETCH_DAYS: int = 7
FETCH_TIMEOUT_SECONDS: int = 8
GUNICORN_TIMEOUT: int = 120
```

### TO-BE
```python
# app/core/config.py
DB_POOL_SIZE: int = 2  # Starter Planæœ€é©å€¤
DB_MAX_OVERFLOW: int = 3
DB_POOL_RECYCLE: int = 900  # 15åˆ†ï¼ˆSupabaseæ¨å¥¨ï¼‰
YF_REFETCH_DAYS: int = 7  # ç¶­æŒ

# è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—å¯¾å¿œã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
FETCH_TIMEOUT_SECONDS: int = 30  # 8â†’30ç§’ï¼ˆé•·æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—å¯¾å¿œï¼‰
GUNICORN_TIMEOUT: int = 60  # 120â†’60ç§’ï¼ˆå®Ÿç”¨çš„ãªå€¤ï¼‰
REQUEST_TIMEOUT_SECONDS: int = 45  # 15â†’45ç§’
YF_REQ_CONCURRENCY: int = 2  # 4â†’2ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
```

---

## 5. ğŸŸ¡ ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤

### WHY
- ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§ã®ä½ä¸‹
- ã©ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ã†ã¹ãã‹ä¸æ˜ç¢º
- ãƒ‡ãƒ—ãƒ­ã‚¤ã‚µã‚¤ã‚ºã®å¢—å¤§

### WHAT
- æœªä½¿ç”¨ãƒ»é‡è¤‡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‰Šé™¤

### AS-IS
```
app/
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ queries.py           # âœ… ä½¿ç”¨ä¸­
â”‚   â”œâ”€â”€ queries_new.py       # âŒ ã‚¨ãƒ©ãƒ¼ã‚ã‚Š
â”‚   â””â”€â”€ queries_optimized.py # âŒ æœªä½¿ç”¨
â”œâ”€â”€ monitoring/              # âŒ é–‹ç™ºç”¨ï¼ˆæœ¬ç•ªä¸è¦ï¼‰
â””â”€â”€ profiling/               # âŒ é–‹ç™ºç”¨ï¼ˆæœ¬ç•ªä¸è¦ï¼‰
```

### TO-BE
```
app/
â””â”€â”€ db/
    â””â”€â”€ queries.py  # ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ç¶­æŒ
```

---

## 6. ğŸŸ¡ render.yamlç’°å¢ƒå¤‰æ•°æ•´ç†

### WHY
- ç’°å¢ƒå¤‰æ•°ãŒæœ€é©åŒ–ã•ã‚Œã¦ã„ãªã„
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒæœ¬ç•ªå‘ã‘ã§ãªã„
- è‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæœªè¨­å®š

### WHAT
- Starter Planå‘ã‘æœ€é©å€¤è¨­å®š
- ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå»¶é•·

### AS-IS
```yaml
# render.yaml
envVars:
  - key: DB_POOL_SIZE
    value: "3"
  - key: DB_MAX_OVERFLOW
    value: "2"
  - key: GUNICORN_TIMEOUT
    value: "180"
```

### TO-BE
```yaml
# render.yaml
services:
  - type: web
    name: stock-api
    env: docker
    plan: starter  # æ˜ç¤ºçš„ã«æŒ‡å®š
    envVars:
      # Supabaseæ¥ç¶šï¼ˆPooler modeæ¨å¥¨ï¼‰
      - key: DATABASE_URL
        sync: false
      
      # æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–
      - key: DB_POOL_SIZE
        value: "2"
      - key: DB_MAX_OVERFLOW
        value: "3"
      - key: DB_POOL_RECYCLE
        value: "900"
      
      # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šï¼ˆè‡ªå‹•å–å¾—å¯¾å¿œï¼‰
      - key: GUNICORN_TIMEOUT
        value: "60"
      - key: FETCH_TIMEOUT_SECONDS
        value: "30"
      - key: REQUEST_TIMEOUT_SECONDS
        value: "45"
      - key: WEB_CONCURRENCY
        value: "2"
      - key: YF_REQ_CONCURRENCY
        value: "2"
      
      # APIè¨­å®šï¼ˆç¶­æŒï¼‰
      - key: API_MAX_SYMBOLS
        value: "50"
      - key: API_MAX_ROWS
        value: "1000000"
```

---

## 7. ğŸŸ¢ ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ç¢ºèª

### WHY
- ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ä¿è¨¼
- ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

### WHAT
- æ—¢å­˜å®Ÿè£…ã®ç¢ºèªã¨æ´»ç”¨

### AS-IS/TO-BE
```python
# app/api/deps.py - ã™ã§ã«å®Ÿè£…æ¸ˆã¿ï¼ˆç¶­æŒï¼‰
async def get_session() -> AsyncGenerator[AsyncSession, None]:
    SessionLocal = _sessionmaker_for(settings.DATABASE_URL)
    async with SessionLocal() as session:
        try:
            yield session
            if session.in_transaction():
                await session.commit()  # âœ… è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ
        except Exception:
            if session.in_transaction():
                await session.rollback()  # âœ… è‡ªå‹•ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
            raise
```

---

## 8. ğŸ”´ æœ€å¤æ—¥è‡ªå‹•æ¤œå‡ºï¼†å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ–°æ©Ÿèƒ½ï¼‰

### WHY
- ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„éå»æ—¥ã‚’æŒ‡å®šã—ãŸå ´åˆã€ç¾åœ¨ã¯ç©ºé…åˆ—ã‚’è¿”ã™
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Œãƒ‡ãƒ¼ã‚¿ãŒãªã„ã€ã®ã‹ã€Œã¾ã å–å¾—ã—ã¦ã„ãªã„ã€ã®ã‹åˆ¤æ–­ã§ããªã„
- æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ã™ã‚‹æœŸé–“ã‚’æ¢ã™å¿…è¦ãŒã‚ã‚‹

### WHAT
- Yahoo Financeã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªæœ€å¤æ—¥ã‚’è‡ªå‹•æ¤œå‡º
- è¦æ±‚æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€åˆ©ç”¨å¯èƒ½ãªå…¨æœŸé–“ã‚’è‡ªå‹•å–å¾—
- åˆå›ã¯æ™‚é–“ãŒã‹ã‹ã‚‹ãŒã€ç¢ºå®Ÿã«ãƒ‡ãƒ¼ã‚¿ã‚’æä¾›

### AS-IS
```python
# app/db/queries.py - ç¾åœ¨ã®å‹•ä½œ
async def ensure_coverage(...):
    # è¦æ±‚ã•ã‚ŒãŸæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦è¡Œ
    df = await fetch_prices_df(symbol=symbol, start=start, end=date_to)
    if df is None or df.empty:
        continue  # é™ã‹ã«ã‚¹ã‚­ãƒƒãƒ— â†’ ç©ºé…åˆ—ã‚’è¿”ã™
```

### TO-BE
```python
# app/db/queries.py - æ–°é–¢æ•°è¿½åŠ 
async def ensure_coverage_with_auto_fetch(
    session: AsyncSession,
    symbols: Sequence[str],
    date_from: date,
    date_to: date,
    refetch_days: int,
) -> Dict[str, Any]:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºä¿ï¼ˆæœ€å¤æ—¥è‡ªå‹•æ¤œå‡ºä»˜ãï¼‰
    """
    result_meta = {"fetched_ranges": {}, "row_counts": {}, "adjustments": {}}
    
    for symbol in symbols:
        # DBã®ç¾åœ¨ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
        cov = await _get_coverage(session, symbol, date_from, date_to)
        
        if not cov.get("first_date") or cov.get("has_gaps"):
            # Yahoo Financeã‹ã‚‰æœ€å¤æ—¥ã‚’æ®µéšçš„ã«æ¢ç´¢
            actual_start = await find_earliest_available_date(symbol, date_from)
            
            if actual_start > date_from:
                result_meta["adjustments"][symbol] = (
                    f"requested {date_from}, actual {actual_start}"
                )
                logger.warning(
                    f"Symbol {symbol}: Auto-adjusting date_from "
                    f"from {date_from} to {actual_start}"
                )
            
            # åˆ©ç”¨å¯èƒ½ãªå…¨æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            logger.info(f"Auto-fetching {symbol} from {actual_start} to {date_to}")
            df = await fetch_prices_df(symbol=symbol, start=actual_start, end=date_to)
            
            if df is not None and not df.empty:
                rows = df_to_rows(df, symbol=symbol, source="yfinance")
                if rows:
                    await session.execute(text(upsert_prices_sql()), rows)
                    result_meta["fetched_ranges"][symbol] = {
                        "from": str(actual_start), "to": str(date_to)
                    }
                    result_meta["row_counts"][symbol] = len(rows)
    
    return result_meta

async def find_earliest_available_date(symbol: str, target_date: date) -> date:
    """
    åŠ¹ç‡çš„ã«æœ€å¤ã®åˆ©ç”¨å¯èƒ½æ—¥ã‚’æ¢ç´¢
    """
    import yfinance as yf
    
    # ã‚ˆãã‚ã‚‹é–‹å§‹æ—¥ã®å€™è£œã‚’è©¦è¡Œ
    test_dates = [
        date(1970, 1, 1),   # Unix epoch
        date(1980, 1, 1),   # å¤šãã®ç±³å›½æ ª
        date(1990, 1, 1),   # 90å¹´ä»£ä¸Šå ´
        date(2000, 1, 1),   # 2000å¹´ä»£
        date(2010, 1, 1),   # æœ€è¿‘ã®IPO
    ]
    
    for test_date in test_dates:
        if test_date >= target_date:
            try:
                # 30æ—¥åˆ†ã®å°ã•ãªãƒ†ã‚¹ãƒˆ
                df = yf.download(
                    symbol,
                    start=test_date,
                    end=test_date + timedelta(days=30),
                    progress=False,
                    timeout=5
                )
                if not df.empty:
                    # å®Ÿéš›ã®æœ€å¤æ—¥ã‚’å–å¾—
                    return df.index[0].date()
            except:
                continue
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šè¦æ±‚æ—¥ä»˜ã¾ãŸã¯2000å¹´ã®ã©ã¡ã‚‰ã‹æ–°ã—ã„æ–¹
    return max(target_date, date(2000, 1, 1))
```

### APIå´ã®ä¿®æ­£
```python
# app/api/v1/prices.py
@router.get("/prices", response_model=List[PriceRowOut])
async def get_prices(
    symbols: str = Query(...),
    date_from: date = Query(..., alias="from"),
    date_to: date = Query(..., alias="to"),
    auto_fetch: bool = Query(True, description="Auto-fetch all available data if missing"),
    session=Depends(get_session),
):
    # ... validation ...
    
    async with session.begin():
        if settings.ENABLE_AUTO_REGISTRATION:
            await ensure_symbols_registered(session, symbols_list)
        
        t0 = time.perf_counter()
        
        if auto_fetch:
            # æ–°æ©Ÿèƒ½ï¼šæœ€å¤æ—¥ã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿è‡ªå‹•å–å¾—
            fetch_meta = await queries.ensure_coverage_with_auto_fetch(
                session=session,
                symbols=symbols_list,
                date_from=date_from,
                date_to=date_to,
                refetch_days=settings.YF_REFETCH_DAYS,
            )
            
            if fetch_meta.get("adjustments"):
                logger.info(f"Date adjustments applied: {fetch_meta['adjustments']}")
        else:
            # å¾“æ¥ã®å‹•ä½œï¼ˆè‡ªå‹•å–å¾—ãªã—ï¼‰
            await queries.ensure_coverage(
                session=session,
                symbols=symbols_list,
                date_from=date_from,
                date_to=date_to,
                refetch_days=settings.YF_REFETCH_DAYS,
            )
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        rows = await queries.get_prices_resolved(
            session=session,
            symbols=symbols_list,
            date_from=date_from,
            date_to=date_to,
        )
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è­¦å‘Š
    dt_ms = int((time.perf_counter() - t0) * 1000)
    if dt_ms > 5000:
        logger.warning(f"Slow initial fetch: {dt_ms}ms (expected for new data)")
    
    return rows
```

---

## ğŸ“Š ä¿®æ­£å„ªå…ˆåº¦ã¨å®Ÿæ–½é †åº

| å„ªå…ˆåº¦ | ãƒ•ã‚¡ã‚¤ãƒ« | ä½œæ¥­å†…å®¹ | æ‰€è¦æ™‚é–“ |
|--------|----------|----------|----------|
| 1 | queries_new.py | å‰Šé™¤ | 1åˆ† |
| 2 | queries.py | è‡ªå‹•å–å¾—æ©Ÿèƒ½è¿½åŠ  | 20åˆ† |
| 3 | prices.py | auto_fetchãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ  | 10åˆ† |
| 4 | engine.py | Supabaseæ¥ç¶šæœ€é©åŒ– | 10åˆ† |
| 5 | entrypoint.sh | ç°¡æ½”åŒ– | 15åˆ† |
| 6 | config.py | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆèª¿æ•´ | 5åˆ† |
| 7 | render.yaml | ç’°å¢ƒå¤‰æ•°æ›´æ–° | 5åˆ† |
| 8 | ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ« | å‰Šé™¤ | 5åˆ† |

**åˆè¨ˆæ‰€è¦æ™‚é–“: ç´„70åˆ†**

---

## âœ… æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ

### å®šé‡çš„åŠ¹æœ
- **APIå¿œç­”æˆåŠŸç‡**: 70% â†’ 99%+
- **DBæ¥ç¶šã‚¨ãƒ©ãƒ¼**: 10å›/æ—¥ â†’ 0å›/æ—¥
- **ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸç‡**: 60% â†’ 95%+
- **ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸç‡**: 50% â†’ 100%ï¼ˆè‡ªå‹•èª¿æ•´ã«ã‚ˆã‚Šï¼‰
- **åˆå›ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“**: N/A â†’ 10-30ç§’ï¼ˆè¨±å®¹ç¯„å›²ï¼‰
- **2å›ç›®ä»¥é™ã®å¿œç­”æ™‚é–“**: 5ç§’ â†’ 100msä»¥ä¸‹

### å®šæ€§çš„åŠ¹æœ
- ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„æœŸé–“ã®è‡ªå‹•åˆ¤å®šã«ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“å‘ä¸Š
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ˜ç¢ºåŒ–ã«ã‚ˆã‚‹ãƒ‡ãƒãƒƒã‚°æ™‚é–“çŸ­ç¸®
- ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç°¡æ½”åŒ–ã«ã‚ˆã‚‹ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ€§å‘ä¸Š
- åˆ¥ã‚¢ãƒ—ãƒªã‹ã‚‰ã®APIå‘¼ã³å‡ºã—å®‰å®šæ€§å‘ä¸Š

---

## ğŸš€ å®Ÿè£…å¾Œã®æ¤œè¨¼é …ç›®

### 1. ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒãƒ†ã‚¹ãƒˆ
```bash
docker-compose up --build

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/healthz

# é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
curl "http://localhost:8000/v1/prices?symbols=AAPL&from=2024-01-01&to=2024-01-31"

# è‡ªå‹•å–å¾—ãƒ†ã‚¹ãƒˆï¼ˆéå»æ—¥æŒ‡å®šï¼‰
curl "http://localhost:8000/v1/prices?symbols=AAPL&from=1990-01-01&to=2024-12-31&auto_fetch=true"
```

### 2. Renderãƒ‡ãƒ—ãƒ­ã‚¤ãƒ†ã‚¹ãƒˆ
```bash
git push origin main
# Renderè‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤å¾…æ©Ÿ

# æœ¬ç•ªç’°å¢ƒãƒ†ã‚¹ãƒˆ
curl https://stock-api.onrender.com/healthz

# è‡ªå‹•å–å¾—æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆï¼ˆåˆå›ã¯30ç§’ç¨‹åº¦ã‹ã‹ã‚‹ï¼‰
curl "https://stock-api.onrender.com/v1/prices?symbols=MSFT&from=1980-01-01&to=2024-12-31"
```

### 3. å¤–éƒ¨ã‚¢ãƒ—ãƒªã‹ã‚‰ã®ãƒ†ã‚¹ãƒˆ
```python
import httpx
import time

# è‡ªå‹•å–å¾—æ©Ÿèƒ½ä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆ
start = time.time()
response = httpx.get(
    "https://stock-api.onrender.com/v1/prices",
    params={
        "symbols": "AAPL,MSFT",
        "from": "1990-01-01",  # å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šå‰
        "to": "2024-12-31",
        "auto_fetch": "true"
    },
    timeout=60.0  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’é•·ã‚ã«è¨­å®š
)
elapsed = time.time() - start

assert response.status_code == 200
data = response.json()
assert len(data) > 0
print(f"Fetched {len(data)} records in {elapsed:.2f} seconds")

# 2å›ç›®ã¯é«˜é€Ÿ
start = time.time()
response = httpx.get(
    "https://stock-api.onrender.com/v1/prices",
    params={
        "symbols": "AAPL,MSFT",
        "from": "1990-01-01",
        "to": "2024-12-31"
    },
    timeout=10.0
)
elapsed = time.time() - start
assert elapsed < 1.0  # 1ç§’ä»¥å†…
```

---

## ğŸ“ è£œè¶³äº‹é …

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœŸå¾…å€¤
```yaml
# åˆå›ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“ï¼ˆauto_fetch=trueï¼‰
çŸ­æœŸé–“ï¼ˆ1å¹´ï¼‰: 3-5ç§’
ä¸­æœŸé–“ï¼ˆ5å¹´ï¼‰: 5-10ç§’
é•·æœŸé–“ï¼ˆ10å¹´ï¼‰: 10-20ç§’
å…¨æœŸé–“ï¼ˆ40å¹´+ï¼‰: 20-40ç§’

# 2å›ç›®ä»¥é™ï¼ˆDBã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ï¼‰
å…¨ã‚±ãƒ¼ã‚¹: 50-200ms
```

### åˆ¶é™äº‹é …
- Yahoo Finance APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«ã‚ˆã‚Šã€å¤§é‡ã‚·ãƒ³ãƒœãƒ«ã®åŒæ™‚å–å¾—ã¯é¿ã‘ã‚‹
- åˆå›å–å¾—æ™‚ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã«æ³¨æ„ï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã‚‚60ç§’ä»¥ä¸Šã«è¨­å®šæ¨å¥¨ï¼‰
- Supabaseç„¡æ–™ãƒ—ãƒ©ãƒ³ã®å ´åˆã€DBã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ500MBï¼‰ã«æ³¨æ„

### ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ‰‹é †
```bash
# Gitã§å‰ã®ã‚³ãƒŸãƒƒãƒˆã«æˆ»ã™
git revert HEAD
git push origin main

# ã¾ãŸã¯ç‰¹å®šã®ã‚³ãƒŸãƒƒãƒˆã«æˆ»ã™
git reset --hard <commit-hash>
git push -f origin main
```

---

**ä½œæˆè€…**: Stock Data Team  
**æœ€çµ‚æ›´æ–°**: 2025å¹´9æœˆ6æ—¥ï¼ˆè‡ªå‹•ãƒ‡ãƒ¼ã‚¿å–å¾—æ©Ÿèƒ½è¿½åŠ ï¼‰